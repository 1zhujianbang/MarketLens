#!/usr/bin/env python3
"""
æµ‹è¯•æ–°é—»å¤„ç†ä¸äº‹ä»¶æ˜ å°„é›†æˆ
"""

import sys
import json
from pathlib import Path
from typing import List, Dict, Any

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°è·¯å¾„
project_root = Path(__file__).parent.parent
sys.path.insert(0, str(project_root))

from src.adapters.sqlite.store import get_store


def simulate_news_processing():
    """æ¨¡æ‹Ÿæ–°é—»å¤„ç†æµç¨‹"""
    print("ğŸ”„ æ¨¡æ‹Ÿæ–°é—»å¤„ç†æµç¨‹")
    
    # è·å– store å®ä¾‹
    store = get_store()
    
    # æ¨¡æ‹Ÿæ–°é—»æ•°æ®
    news_data = {
        "id": "test_news_001",
        "source": "test_source",
        "title": "æµ‹è¯•æ–°é—»æ ‡é¢˜",
        "content": "è¿™æ˜¯æµ‹è¯•æ–°é—»çš„å†…å®¹ï¼ŒåŒ…å«ä¸€äº›é‡è¦çš„äº‹ä»¶ä¿¡æ¯ã€‚",
        "timestamp": "2025-12-19T10:00:00Z"
    }
    
    # æ¨¡æ‹Ÿæå–çš„äº‹ä»¶æ•°æ®
    extracted_events = [
        {
            "abstract": "æµ‹è¯•äº‹ä»¶1",
            "event_summary": "è¿™æ˜¯ä¸€ä¸ªæµ‹è¯•äº‹ä»¶çš„æ‘˜è¦",
            "entities": ["å®ä½“A", "å®ä½“B"],
            "entities_original": ["Entity A", "Entity B"],
            "event_types": ["æµ‹è¯•ç±»å‹"],
        },
        {
            "abstract": "æµ‹è¯•äº‹ä»¶2",
            "event_summary": "è¿™æ˜¯å¦ä¸€ä¸ªæµ‹è¯•äº‹ä»¶çš„æ‘˜è¦",
            "entities": ["å®ä½“C", "å®ä½“D"],
            "entities_original": ["Entity C", "Entity D"],
            "event_types": ["æµ‹è¯•ç±»å‹2"],
        }
    ]
    
    # æ„é€ æ–°é—»å…¨å±€ID
    global_news_id = f"{news_data['source']}:{news_data['id']}"
    print(f"ğŸ“° å¤„ç†æ–°é—»: {global_news_id}")
    
    # æ¨¡æ‹Ÿäº‹ä»¶å­˜å‚¨è¿‡ç¨‹
    print("ğŸ’¾ å­˜å‚¨æå–çš„äº‹ä»¶...")
    try:
        store.upsert_events(extracted_events, source=news_data['source'], reported_at=news_data['timestamp'])
        print("âœ… äº‹ä»¶å­˜å‚¨æˆåŠŸ")
    except Exception as e:
        print(f"âŒ äº‹ä»¶å­˜å‚¨å¤±è´¥: {e}")
        return False
    
    # è·å–å­˜å‚¨çš„äº‹ä»¶IDï¼ˆé€šè¿‡äº‹ä»¶æ‘˜è¦è®¡ç®—ï¼‰
    event_mappings = []
    for event in extracted_events:
        # è®¡ç®—äº‹ä»¶IDï¼ˆä¸SQLiteStoreä¸­çš„canonical_event_idä¸€è‡´ï¼‰
        abstract = event["abstract"]
        event_id = __import__('hashlib').sha1(f"evt:{abstract}".encode("utf-8")).hexdigest()
        event_mappings.append((global_news_id, event_id))
        print(f"  - äº‹ä»¶: {abstract} -> ID: {event_id}")
    
    # å­˜å‚¨æ–°é—»IDåˆ°äº‹ä»¶IDçš„æ˜ å°„
    print("ğŸ”— å­˜å‚¨æ–°é—»åˆ°äº‹ä»¶çš„æ˜ å°„å…³ç³»...")
    try:
        count = store.add_news_event_mappings(event_mappings)
        print(f"âœ… æˆåŠŸå­˜å‚¨ {count} ä¸ªæ˜ å°„å…³ç³»")
    except Exception as e:
        print(f"âŒ æ˜ å°„å…³ç³»å­˜å‚¨å¤±è´¥: {e}")
        return False
    
    # éªŒè¯æ˜ å°„å…³ç³»
    print("ğŸ” éªŒè¯æ˜ å°„å…³ç³»...")
    try:
        # æ ¹æ®æ–°é—»IDæŸ¥è¯¢äº‹ä»¶ID
        event_ids = store.get_events_by_news_id(global_news_id)
        print(f"  é€šè¿‡æ–°é—»ID {global_news_id} æŸ¥è¯¢åˆ° {len(event_ids)} ä¸ªäº‹ä»¶ID: {event_ids}")
        
        # æ ¹æ®äº‹ä»¶IDæŸ¥è¯¢æ–°é—»ID
        if event_ids:
            news_ids = store.get_news_by_event_id(event_ids[0])
            print(f"  é€šè¿‡äº‹ä»¶ID {event_ids[0]} æŸ¥è¯¢åˆ° {len(news_ids)} ä¸ªæ–°é—»ID: {news_ids}")
        
        return True
    except Exception as e:
        print(f"âŒ æ˜ å°„å…³ç³»éªŒè¯å¤±è´¥: {e}")
        return False


def main():
    """ä¸»å‡½æ•°"""
    print("ğŸš€ å¼€å§‹æµ‹è¯•æ–°é—»å¤„ç†ä¸äº‹ä»¶æ˜ å°„é›†æˆ")
    
    try:
        success = simulate_news_processing()
        if success:
            print("\nâœ… é›†æˆæµ‹è¯•é€šè¿‡!")
            return 0
        else:
            print("\nâŒ é›†æˆæµ‹è¯•å¤±è´¥!")
            return 1
    except Exception as e:
        print(f"\nğŸ’¥ æµ‹è¯•è¿‡ç¨‹ä¸­å‘ç”Ÿé”™è¯¯: {e}")
        import traceback
        traceback.print_exc()
        return 1


if __name__ == "__main__":
    sys.exit(main())